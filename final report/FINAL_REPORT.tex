% HEAR-UI Final Report
% Author: Adelia Manafov, Artem Mozharov, Niels Kuhl
% Date: December 18, 2025
% Format: ACL Conference Style (max 8 pages)

\documentclass[11pt,a4paper,twocolumn]{article}
\usepackage{acl}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{url}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{listings}

% Footer with centered page numbers
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\setlength{\columnsep}{12pt}

% Code listing settings
\lstset{
  basicstyle=\ttfamily\footnotesize,
  breaklines=true,
  frame=single,
  language=Python,
  showstringspaces=false,
  commentstyle=\color{gray},
  keywordstyle=\color{blue}
}

% Define YAML language for listings
\lstdefinelanguage{yaml}{
  keywords={true,false,null,y,n},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={},
  ndkeywordstyle=\color{blue}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{\#},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{gray}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}

\title{HEAR-UI: Explainable AI-Powered Decision Support for Cochlear Implant Success Prediction}

\author{
  Adelia Manafov\textsuperscript{1} \and 
  Artem Mozharov\textsuperscript{1} \and 
  Niels Kuhl\textsuperscript{1} \\
  		extsuperscript{1}University of Marburg, Germany \\
  	{\{manafova, mozharoa, kuhl\}@students.uni-marburg.de} \\
  Supervisors: Prof. Dr. Christin Seifert; M.Sc. Khawla Elhadri
}

\begin{document}
\maketitle

\begin{abstract}
Cochlear implants (CI) can significantly improve hearing for selected patients, but determining suitable candidates requires careful clinical assessment. We present HEAR-UI, an AI-powered clinical decision support system that predicts CI success probability (0-100\%) and provides explainable model outputs using SHAP-based feature importance analysis. The system integrates a 68-feature Logistic Regression classifier with preprocessing, a FastAPI REST API backend, PostgreSQL database, and a Vue.js 3 frontend. Our implementation achieves 72\% test coverage across 268 automated tests, supports real-time predictions with sub-200ms latency, and provides interpretable explanations for clinical decision-making. We demonstrate deployment-ready architecture using Docker Compose, comprehensive CI/CD pipelines via GitHub Actions, and validated the system with 5 real patient cases. The project emphasizes transparency, reproducibility, and explainability — critical requirements for clinical AI systems. All code, documentation, and deployment configurations are openly available.
\end{abstract}

\section{Introduction}

\subsection{Problem Statement}
Cochlear implantation is a transformative medical intervention that can restore hearing to profoundly deaf patients. However, the procedure involves significant risks, costs, and post-operative rehabilitation requirements. Not all patients achieve successful outcomes, and predicting which candidates will benefit most remains a clinical challenge~\cite{wilson2008cochlear,lenarz2018cochlear}.

Current clinical practice relies primarily on qualitative assessments and clinician experience. While effective, this approach lacks systematic integration of historical outcome data and quantitative risk-benefit analysis. There is a clear need for data-driven tools that can:
\begin{itemize}
  \item Predict individual patient success probability
  \item Explain \textit{which} patient factors drive predictions
  \item Integrate seamlessly into clinical workflows
  \item Maintain transparency and interpretability
\end{itemize}

\subsection{Research Questions}
This project addresses three core research questions:

\textbf{RQ1:} Can a clinical dataset with heterogeneous patient features be transformed into a robust, interpretable machine learning model for CI success prediction?

\textbf{RQ2:} Can post-hoc explainability methods (SHAP) be integrated into a deployed clinical decision support system to provide actionable insights for clinicians?

\textbf{RQ3:} What architectural patterns and deployment strategies enable production-ready, maintainable AI systems for clinical decision support?

\subsection{Contributions}
Our key contributions are:
\begin{enumerate}
  \item A complete, deployment-ready clinical decision support system with frontend, backend, and database
  \item Integration of SHAP explanations for interpretable ML predictions
  \item Comprehensive testing strategy (268 tests, 72\% coverage)
  \item Reproducible Docker-based deployment
  \item Validated CI/CD pipelines with automated testing
  \item Open-source codebase with extensive documentation
\end{enumerate}

\section{Related Work}

\subsection{Explainable AI in Healthcare}
Explainable AI (XAI) has become critical for clinical decision support systems. Lundberg and Lee~\cite{lundberg2017shap} introduced SHAP (SHapley Additive exPlanations), a unified framework for interpreting model predictions based on game-theoretic Shapley values. SHAP provides both local (per-prediction) and global (model-wide) explanations, making it particularly suitable for clinical applications where understanding \textit{why} a model makes specific predictions is as important as the prediction itself.

Ribeiro et al.~\cite{ribeiro2016lime} proposed LIME (Local Interpretable Model-agnostic Explanations), an alternative explanation method that approximates any black-box model locally with an interpretable model. While LIME is model-agnostic, SHAP offers stronger theoretical guarantees and consistent feature attribution~\cite{molnar2022interpretable}.

Rudin~\cite{rudin2019stop} argues that in high-stakes domains like healthcare, inherently interpretable models (e.g., logistic regression, decision trees) should be preferred over post-hoc explanations of black-box models. Our work aligns with this philosophy by using Logistic Regression as the primary classifier.

\subsection{AI in Medicine}
Topol~\cite{topol2019high} provides a comprehensive overview of AI applications in medicine, emphasizing the convergence of human and artificial intelligence. He highlights that successful clinical AI systems must prioritize:
\begin{itemize}
  \item Transparency and interpretability
  \item Integration with existing clinical workflows
  \item Validation on diverse patient populations
  \item Ethical considerations and bias mitigation
\end{itemize}

Shortliffe and Sepúlveda~\cite{shortliffe2018clinical} discuss clinical decision support systems (CDSS) in the era of AI, noting that adoption is often hindered by lack of trust, poor integration, and insufficient explanation of recommendations.

\subsection{Cochlear Implant Outcome Prediction}
Wilson and Dorman~\cite{wilson2008cochlear} provide a comprehensive review of cochlear implant technology and outcomes, noting substantial variability in patient success rates. Lenarz~\cite{lenarz2018cochlear} discusses state-of-the-art CI technology and emphasizes the need for better patient selection criteria.

Several studies have attempted to predict CI outcomes using patient demographics, audiological measures, and imaging data~\cite{wilson2008cochlear}. However, most rely on traditional statistical methods (e.g., logistic regression, Cox proportional hazards) without modern ML explainability tools.

\subsection{Gap in Literature}
To our knowledge, no prior work has demonstrated a \textit{complete}, \textit{deployed}, \textit{explainable} CI decision support system with:
\begin{itemize}
  \item Modern web-based architecture (REST API, Vue.js frontend)
  \item Real-time SHAP explanations
  \item Comprehensive automated testing
  \item Docker-based reproducible deployment
  \item Open-source availability
\end{itemize}

HEAR-UI fills this gap by providing a production-ready reference implementation for clinical AI systems.

\section{System Architecture}

\subsection{Overview}
HEAR-UI follows a modern microservices architecture with three primary components (Figure~\ref{fig:architecture}):

\begin{enumerate}
  \item \textbf{Backend (FastAPI):} REST API serving predictions, explanations, and patient data management
  \item \textbf{Frontend (Vue.js 3):} Single-page application for clinicians
  \item \textbf{Database (PostgreSQL 12):} Persistent storage for patients, predictions, and feedback
\end{enumerate}

All components are containerized using Docker and orchestrated via Docker Compose, ensuring reproducible deployment across development, testing, and production environments.

\subsection{Backend Architecture}
The FastAPI backend consists of:
\begin{itemize}
  \item \textbf{API Routes} (\texttt{app/api/routes/}): RESTful endpoints for predictions, explainer, patients, feedback, and utilities
  \item \textbf{Core Logic} (\texttt{app/core/}): Model wrapper, SHAP explainer, preprocessor, background data generation
  \item \textbf{Database Models} (\texttt{app/models/}): SQLModel schemas for patients, predictions, feedback
  \item \textbf{Tests} (\texttt{app/tests/}): 202 unit and integration tests
\end{itemize}

\textbf{Technology Stack:}
\begin{itemize}
  \item FastAPI 0.115.5 (async, auto-generated OpenAPI docs)
  \item Pydantic 2.10.3 (data validation)
  \item SQLModel 0.0.22 (type-safe ORM)
  \item Alembic 1.14.0 (database migrations)
  \item scikit-learn 1.5.2 (ML pipeline)
  \item SHAP 0.46.0 (explainability)
\end{itemize}

\subsection{Frontend Architecture}
The Vue.js 3 frontend provides:
\begin{itemize}
  \item \textbf{Patient Management:} Search, view, create patients
  \item \textbf{Prediction Interface:} Request predictions for specific patients
  \item \textbf{SHAP Visualization:} Bar charts showing feature importance
  \item \textbf{Feedback System:} Capture clinician agreement/disagreement with predictions
\end{itemize}

\textbf{Technology Stack:}
\begin{itemize}
  \item Vue.js 3.5.13 (Composition API)
  \item TypeScript 5.6.3 (type safety)
  \item Vite 6.0.1 (build tool, HMR)
  \item Vuetify 3.7.5 (Material Design components)
  \item Playwright 1.48.2 (E2E testing)
\end{itemize}

\subsection{Database Schema}
PostgreSQL stores:
\begin{itemize}
  \item \textbf{Patients:} Demographics, audiological data, implant details (68 features after preprocessing)
  \item \textbf{Predictions:} Cached predictions with timestamps
  \item \textbf{Feedback:} Clinician responses to predictions
\end{itemize}

Alembic manages schema migrations, ensuring version control and reproducible deployments.

\subsection{API Design}
RESTful endpoints follow industry best practices (Table~\ref{tab:api-endpoints}). All endpoints return JSON responses with HTTP status codes. OpenAPI/Swagger documentation is auto-generated at \texttt{/docs}.

\input{tables/api_endpoints}

\section{Data and Preprocessing}

\subsection{Dataset Description}
The dataset consists of de-identified cochlear implant patient records including demographics, audiological measures (onset type, duration, cause), pre-operative symptoms, and implant details. After preprocessing and one-hot encoding, 68 features are generated. Five fully annotated test patients are publicly available; the full training cohort remains private for GDPR compliance.

\subsection{Preprocessing Pipeline}
Preprocessing (\texttt{backend/app/core/preprocessor.py}) includes: (1) column mapping from German labels to English, (2) domain-informed default imputation, (3) one-hot encoding with deterministic feature ordering, (4) StandardScaler for numerical features. The \texttt{preprocess()} function accepts raw dictionaries and returns numpy arrays aligned with the trained pipeline.



\section{Machine Learning Method}

\subsection{Model Selection}
We chose \textbf{Logistic Regression} as the primary classifier for several reasons:
\begin{enumerate}
  \item \textbf{Interpretability:} Coefficients directly indicate feature importance
  \item \textbf{Calibration:} Outputs are naturally probabilistic (0-1 scale)
  \item \textbf{Clinical Acceptance:} Widely understood by medical professionals
  \item \textbf{Baseline Performance:} Strong baseline for high-dimensional data
  \item \textbf{Explainability:} Linear models work seamlessly with SHAP
\end{enumerate}

Rudin~\cite{rudin2019stop} argues that in high-stakes domains, inherently interpretable models should be preferred over black-box models with post-hoc explanations. Logistic Regression satisfies this requirement.

\subsection{Model Architecture and Training}
The model is a scikit-learn Pipeline: StandardScaler + OneHotEncoder → LogisticRegression (L1 penalty, C=10.0, liblinear solver). Serialization via \texttt{joblib} ensures the complete preprocessing pipeline is preserved. Hyperparameters were tuned for interpretability and regularization balance.

\subsection{SHAP Explainability}
We integrate SHAP~\cite{lundberg2017shap} for per-prediction feature importance. The explainer (\texttt{backend/app/core/shap\_explainer.py}) uses \texttt{LinearExplainer} for logistic regression, with synthetic background data for stabilization. API responses include \texttt{base\_value} (average prediction), \texttt{shap\_values} (feature attributions), and \texttt{top\_features} ranked by importance.

\section{Evaluation}

\subsection{Testing Strategy}
We implement a comprehensive multi-level testing strategy (Table~\ref{tab:testing}):

\input{tables/coverage_summary}

Tests cover model loading, SHAP alignment, API endpoints, database CRUD, security (password hashing), and end-to-end workflows. Coverage analysis (\texttt{pytest-cov}) focuses on production code, achieving 72\% coverage~\cite{sommerville2015software}.

\subsection{CI/CD Pipeline}
GitHub Actions automate testing and deployment:
\begin{itemize}
  \item \textbf{Linting:} Ruff (Python), Biome (TypeScript)
  \item \textbf{Unit Tests:} pytest on every push/PR
  \item \textbf{E2E Tests:} Playwright on PR to main
  \item \textbf{Docker Build:} Validate containers build successfully
  \item \textbf{Coverage Report:} Generate HTML reports for review
\end{itemize}

All workflows are defined in \texttt{.github/workflows/}.

\subsection{System Validation}
We validated with 5 real patient cases (Table~\ref{tab:patient-validation}). Postlingual onset strongly predicts success; syndromal causes correlate with lower rates. Predictions are reproducible and SHAP explanations align with clinical intuition.

\input{tables/patient_validation}

\subsection{Performance Metrics}
Prediction latency averages 150ms; SHAP explanation 350ms. Async FastAPI with PostgreSQL pooling supports concurrent requests; Docker Compose scales to multiple backend replicas.

\section{Results and Discussion}

\subsection{Implementation Status}
Fully implemented: REST API (17 endpoints), ML prediction with SHAP, PostgreSQL database, Vue.js frontend, Docker deployment, CI/CD (7 workflows). Testing: 268 tests (98.5\% pass), 72\% coverage, all workflows validated end-to-end.

\subsection{Key Findings}

\subsubsection{Key Findings}
SHAP analysis identifies top predictive features: hearing loss onset (postlingual > perilingual > prelingual), contralateral ear status, cause (syndromal negative), deafness duration, and age. These align with clinical literature~\cite{wilson2008cochlear,lenarz2018cochlear}. System handles missing values, ensures deterministic predictions, and gracefully manages edge cases.

\subsection{Limitations}
\textbf{Data:} Small public sample (5 patients), binary labels may oversimplify outcomes, single-center data limits generalizability. \textbf{Model:} Linearity assumption may miss complex patterns; calibration analysis needed~\cite{niculescu2005predicting}. \textbf{Deployment:} Lacks authentication, audit logging, and production monitoring. Future work includes multi-center validation, calibration testing, non-linear model comparison, and prospective clinical studies.

\section{Deployment and Reproducibility}
All components are containerized (Docker Compose orchestrates backend, frontend, PostgreSQL). Deployment: clone repository, configure \texttt{.env}, run \texttt{docker compose up}, execute migrations. Documentation includes README, technical docs, API guides (Swagger), and validation reports. Reproducibility: fixed dependencies, deterministic features, random seeds, CI/CD validation.

\section{Conclusion}
HEAR-UI is a deployment-ready clinical decision support system integrating interpretable ML (Logistic Regression, 68 features), SHAP explainability, modern web architecture (FastAPI, Vue.js, PostgreSQL), comprehensive testing (268 tests, 72\% coverage), and Docker deployment. Validation with 5 patients shows reproducible predictions (< 200ms latency) with clinically intuitive SHAP explanations.

The system advances clinical AI by demonstrating complete integration, prioritizing explainability, and emphasizing transparency through open-source release. Future work includes multi-center validation, calibration analysis, security enhancements, and prospective clinical studies. HEAR-UI serves as a reference implementation showing that explainability and performance are compatible when paired with rigorous software engineering practices.

\section*{Declaration of Generative AI Usage}
Generative AI (GitHub Copilot, Claude) was used for:
\begin{itemize}
  \item Code completion and boilerplate generation
  \item Documentation drafting and structuring
  \item Test case generation
  \item LaTeX formatting and bibliography management
\end{itemize}

All AI-generated content was reviewed, edited, and validated by the authors. Technical descriptions were verified against repository code. No AI-generated code was committed without human review and testing.

\section*{Acknowledgements}
We thank our supervisors, Prof. Dr. Christin Seifert and M.Sc. Khawla Elhadri, for their continuous guidance and invaluable feedback throughout the project.

\section*{Contribution Statement}
\textbf{Adelia Manafov:}
\begin{itemize}
  \item Backend architecture and implementation (FastAPI, SQLModel)
  \item ML model integration and preprocessing pipeline
  \item SHAP explainer wrapper and API integration
  \item Database schema design and migrations (Alembic)
  \item CI/CD pipeline setup (GitHub Actions)
  \item Testing strategy and implementation (pytest, 202 backend tests)
  \item Docker Compose configuration
  \item System validation and documentation
  \item Final report preparation
\end{itemize}

\textbf{Artem Mozharov:}
\begin{itemize}
  \item Frontend architecture and implementation (Vue.js 3, TypeScript)
  \item UI/UX design (Vuetify components)
  \item Patient management interface
  \item Prediction and SHAP visualization components
  \item I18n (internationalization) setup
  \item E2E testing (Playwright, 18 tests)
  \item Frontend documentation
  \item Demo video preparation
\end{itemize}

\textbf{Niels Kuhl:}
\begin{itemize}
  \item Clinical domain expertise
  \item Dataset provision and annotation
  \item Validation of clinical relevance
\end{itemize}

\bibliographystyle{acl_natbib}
\bibliography{custom}



\end{document}
