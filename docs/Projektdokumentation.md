# HEARâ€‘Projekt â€” MVP, Features & Zeitplan

Kurzbeschreibung:
Eine Webanwendung zur UnterstÃ¼tzung Ã¤rztlicher Entscheidungen bei Cochleaâ€‘Implantaten. Die Anwendung liefert eine Vorhersage zur Erfolgswahrscheinlichkeit, erklÃ¤rt die Vorhersage (z. B. mit SHAP) und ermÃ¶glicht klinisches Feedback.

## Wichtigste Befehle (kurz)

Hier sind die wichtigsten Kommandos fÃ¼r Entwicklung, Demo und Betrieb. Weiter unten im Dokument noch einmal komplett in Kontext vorhanden.

- **`cd hear-ui`**
- **`docker compose up -d --build`**
- **`docker compose down`**
- **`docker compose logs --follow --tail 200 backend`**
- **`curl -v http://localhost:8000/api/v1/utils/health-check/`**
- **`PGPASSWORD=change_me psql -h localhost -p 5433 -U postgres -d app`**
- **`docker compose exec backend alembic upgrade head`**
- **`docker cp mydata.csv hear-ui-db-1:/tmp/mydata.csv`**
- **`docker exec -it hear-ui-db-1 psql -U postgres -d app -c "\copy patients FROM '/tmp/mydata.csv' WITH (FORMAT csv, HEADER true)"`**


---

## Inhaltsverzeichnis

- [Ziel des Projekts](#ziel-des-projekts)
- [KurzÃ¼berblick / MVP](#kurzuberblick-mvp)
- [Komponenten](#komponenten)
- [Werkzeuge - Ãœbersicht](#werkzeuge-uebersicht)
- [API-Endpunkte](#api-endpunkte-Ã¼bersicht)
- [Zeitplan](#zeitplan)
- [Demo](#how-to-demo)
- [Aktueller System-Status](#system-status)
- [Aktueller Projektstand](#aktueller-projektstand-stand-30112025)

---

<a id="ziel-des-projekts"></a>
## Ziel des Projekts

Ziel ist ein schnell einsatzfÃ¤higes MVP fÃ¼r klinische UnterstÃ¼tzung: Eingabe â†’ Vorhersage â†’ ErklÃ¤rung. 

Persistenz von Feedback und erweiterte Features folgen schrittweise.

---

<a id="kurzuberblick-mvp"></a>
## KurzÃ¼berblick / MVP (konkret)

FÃ¼r das MVP konzentrieren wir uns auf einen klaren End-to-End-Flow:

  - Frontend: Formular zum Eingeben einer Person (Patientendaten).
  - Backend: 
      - Predictâ€‘Endpoint (POST /api/v1/predict) â†’ gibt Wahrscheinlichkeit + Label zurÃ¼ck.
      - SHAPâ€‘ErklÃ¤rungen â†’ strukturierte SHAPâ€‘Werte (JSON) oder base64â€‘Plot.
      - Feedbackâ€‘Endpoint (POST /api/v1/feedback) â†’ persistiert Feedback in Postgres.
  - Datenpersistenz: Postgres speichert Feedback + ggf. Patienten/Tabelle. CSVâ€‘Import nur fÃ¼rs initiale Seeding mÃ¶glich.
  - Reproduzierbarkeit: komplette Umgebung per docker-compose.

=> Ziel: Damit kÃ¶nnen wir bereits echte Ergebnisse zeigen, auch wenn noch nicht alle Features ausgebaut sind.

**Zusammenfassung:**

  Der minimale Funktionsumfang enthÃ¤lt:
      - ein valides Eingabeformular im Frontend
      
      - einen funktionierenden Predict-Endpoint
      
      - eine einfache ErklÃ¤rung (z. B. SHAP-Ranking oder Barplot)
      
      - eine Feedback-Tabelle mit Storage in PostgreSQL
      
      - ein reproduzierbares Setup Ã¼ber Docker-Compose

---

<a id="komponenten"></a>
## Komponenten (Kurz)

- Frontend: Eingabe, Ergebnisanzeige, Visualisierung, Feedbackâ€‘UI
- Backend: API, Modellâ€‘Wrapper, ErklÃ¤rungsâ€‘Pipeline, Persistenz
- Datenbank: PostgreSQL fÃ¼r Feedback und Logs (Pseudonymisierung beachten)
- DevOps: Containerisierung, CI for tests & linting

---

<a id="werkzeuge-uebersicht"></a>
## Werkzeuge - Ãœbersicht

<!-- Frontend: hellblau -->
<h3 style="background:#e6f7ff;padding:6px;border-left:6px solid #66b3ff">Frontend</h3>
<table>
  <thead>
    <tr style="background:#f0f8ff">
      <th>Tool</th>
      <th>Was es macht</th>
      <th>Warum wir es wÃ¤hlen</th>
      <th>Im Repo?</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Vue 3 (konkrete Verison aus Vue.js)</td>
      <td>Frontend-JavaScript-Framework</td>
      <td>einfach zu lernen + unterstÃ¼tzt Komponenten, die die Darstellung von Vorhersagen, SHAP-Visualisierungen oder Feedback-Buttons modular machen + gut kombinierbar mit FastAPI Ã¼ber RESTful APIs</td>
      <td>Ja â€” das Frontend verwendet Vue 3 (siehe <code>frontend/package.json</code>)</td>
    </tr>
    <tr>
      <td>TypeScript</td>
      <td>Statische Typisierung fÃ¼r JS</td>
      <td>Wartbarkeit, frÃ¼here Fehlererkennung</td>
      <td>Ja â€” wird weiterverwendet</td>
    </tr>
    <tr>
      <td>Vite</td>
      <td>Build-Tool und Entwicklungsserver speziell fÃ¼r Frameworks wie Vue 3</td>
      <td>schnelleres Frontend-Development + einfache Integration mit Vue 3 + Produktion-ready (kÃ¶nnen die App einfach bauen und in Docker deployen)</td>
      <td>Ja â€” <code>frontend/package.json</code></td>
    </tr>
    <tr>
      <td>pnpm</td>
      <td>Paketmanager fÃ¼r JavaScript/TypeScript</td>
      <td>leichtgewichtiger, schnellerer und platzsparender fÃ¼r grÃ¶ÃŸere Projekte + wir verwenden pnpm in diesem Projekt</td>
      <td>Ja â€” `frontend/pnpm-lock.yaml` wurde erstellt und ist committed (pnpm ist das bevorzugte Tool fÃ¼r das Frontend).</td>
    </tr>
    <tr>
      <td>UIâ€‘Library</td>
      <td>Komponentenâ€‘Bibliothek fÃ¼r Vue + vorgefertigte, getestete Komponenten (Buttons, Inputs, Tabellen, Dialoge, Formulare, Layouts, Themes)</td>
      <td>Schneller Aufbau von konsistenten, zugÃ¤nglichen UIâ€‘Elementen</td>
      <td>Ja â€” im Frontend ist <code>@chakra-ui/react</code> als UIâ€‘Bibliothek installiert (Reactâ€‘UI).</td>
    </tr>
    <tr>
      <td>Playwright</td>
      <td>End-to-End (E2E) Testing-Framework, das Browser automatisiert steuert, um Webanwendungen zu testen (Ã¶ffnet echte Browser und fÃ¼hrt Aktionen wie ein echter Nutzer aus)</td>
      <td>App hat ein Frontend (React) + Backend (FastAPI)</td>
      <td>Ja â€” <code>@playwright/test</code> ist in <code>frontend/package.json</code> aufgefÃ¼hrt und es gibt eine <code>playwright.config.ts</code>.</td>
    </tr>
    <tr>
      <td>Vitest</td>
      <td>Testing-Framework fÃ¼r JavaScript/TypeScript (speziell fÃ¼r Vite-Projekte + Vue 3)</td>
      <td>schnell + kann zusammen mit Playwright fÃ¼r End-to-End-Tests genutzt werden</td>
      <td>Ja â€” Vitest ist als Frontendâ€‘Unitâ€‘Testâ€‘Runner hinzugefÃ¼gt.</td>
    </tr>
  </tbody>
</table>

<!-- Backend: hellgrÃ¼n -->
<h3 style="background:#f0fff0;padding:6px;border-left:6px solid #6fdc6f">Backend und DB</h3>
<table>
  <thead>
    <tr style="background:#f7fff7">
      <th>Tool</th>
      <th>Was es macht</th>
      <th>Warum wir es wÃ¤hlen</th>
      <th>Im Repo?</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>FastAPI</td>
      <td>Webâ€‘Framework fÃ¼r APIs (Pydantic)</td>
      <td>OpenAPI, gute Performance, schnell entwickelbar</td>
      <td>Ja â€” Backendâ€‘Projekt mit FastAPI ist vorhanden (siehe <code>backend/pyproject.toml</code>).</td>
    </tr>
    <tr>
      <td>PDM (Python Dependency Manager)</td>
      <td>Tool, um Python-Projekte zu verwalten + sorgt dafÃ¼r, dass Entwicklungsumgebung stabil ist</td>
      <td>Wir haben ein FastAPI-Backend, Datenbank-Module (PostgreSQL, SQLModel), Testing-Frameworks â†’ hilft sicherzustellen, dass alle diese Pakete in der richtigen Version verfÃ¼gbar sind.</td>
      <td>Ja â€” genutzt in Docs/ run commands</td>
    </tr>
    <tr>
      <td>SQLModel</td>
      <td>Biblitohek fÃ¼r Datenbankenanbindung</td>
      <td>SQLModel: moderner Hybrid vs. SQLAlchemy (mehr manuell machen, fÃ¼r komplexere features), in SQLModel ist schon alles definiert, was man typischerweise in FastAPI-Projekten braucht. SQLModel = SQLAlchemy + Pydantic (bequemere Typen/Validierung in FastAPI)</td>
      <td>Ja â€” <code>backend/pyproject.toml</code></td>
    </tr>
    <td>Alembic</td>
      <td>saubere Verwaltung und Weiterentwicklung der Datenbank fÃ¼r spÃ¤tere Zeit</td>
      <td>Datenbankverwaltung reproduzierbar, versioniert und weniger fehleranfÃ¤llig â†’ ohne Alembic wÃ¼rde im MVP zwar starten kÃ¶nnen, spÃ¤tere Anpassungen/ neue features kÃ¶nnten aber schnell zum Problem werden</td>
      <td>Ja â€” Alembic ist im Backend eingerichtet. Die Compose/Containerâ€‘Runs verwenden die Datei <code>backend/alembic.ini</code> (diese wird ins Image kopiert und vom Startskript verwendet). Die Entwicklerâ€‘Referenz wurde nach <code>backend/app/alembic.ini.example</code> verschoben.</td>
    </tr>
    <tr>
      <td>Postgres</td>
      <td>Daten speichern und abrufen</td>
      <td>speichern der Nutzerdaten, Feedbacks + persistente Daten fÃ¼r Modell-ErklÃ¤rungen (wenn zb SHAP-Ergebnisse langfristig speichern) + UnterstÃ¼tzung fÃ¼r Webanwendung (Backend ruft DB ab, Frontend zeigt Daten an, REST-API greift auf die DB zu)</td>
      <td>Ja â€” DBâ€‘Treiber (<code>psycopg</code>, <code>asyncpg</code>) sind als AbhÃ¤ngigkeiten im Backend gelistet; <code>docker-compose.yml</code> enthÃ¤lt einen Postgresâ€‘Dienst.</td>
    </tr>
    <tr>
      <td>Adminer?</td>
      <td>Webâ€‘GUI fÃ¼r Datenbanken; schnell Tabellen/Zeilen prÃ¼fen; SQLâ€‘Queries ausfÃ¼hren oder Debugging von Daten</td>
      <td>FÃ¼r Debug/Demo; zum visuellen PrÃ¼fen nutzen</td>
      <td>Im Browser: http://localhost:8080</td>
    </tr>
  </tbody>
</table>

<!-- Models & Explainability: gelb -->
<h3 style="background:#fff7e6;padding:6px;border-left:6px solid #ffcc66">Modelle und Explainability</h3>
<table>
  <thead>
    <tr style="background:#fffaf0">
      <th>Tool / Typ</th>
      <th>Was es macht</th>
      <th>Warum wir es wÃ¤hlen</th>
      <th>Im Repo?</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>SHAP</td>
      <td>Framework zur ErklÃ¤rung von Modellvorhersagen, sowohl lokal (einzelner Patient) als auch global (alle Patienten)</td>
      <td>klinisch verstÃ¤ndliche Featureâ€‘Ranglisten + Ã„rzte kÃ¶nnen nachvollziehen, warum die KI eine Operation empfiehlt oder nicht</td>
      <td>Ja â€” <code>shap</code> wurde als Backendâ€‘Dependency hinzugefÃ¼gt und der Predictâ€‘Endpoint nutzt SHAP (mit Fallback, falls die Laufzeitumgebung SHAP nicht verfÃ¼gbar ist).<br/>
      Hinweis: <strong>NumPy ist Pflicht</strong> fÃ¼r SHAP und das Modellâ€‘Handling, weil:<ul>
        <li>Modelle Inputâ€‘Daten als NumPyâ€‘Arrays erwarten.</li>
        <li>SHAP intern NumPy verwendet und ohne NumPy nicht funktioniert.</li>
        <li>Viele Datenvorbereitungsschritte (Skalierung, Vektorisierung) NumPy nutzen.</li>
      </ul>
      Status: <em>NumPy wurde bereits installiert</em> (falls die Laufzeitumgebung diese AbhÃ¤ngigkeit hat, nutzt der Endpoint echte SHAPâ€‘ErklÃ¤rungen; andernfalls greift der vorhandene Fallback).</td>
    </tr>
  </tbody>
</table>

<!-- Tests & Quality: rosa -->
<h3 style="background:#fff0f6;padding:6px;border-left:6px solid #ff99cc">Verbesserung der Codeâ€‘QualitÃ¤t + Tests</h3>
<table>
  <thead>
    <tr style="background:#fff8fb">
      <th>Tool</th>
      <th>Was es macht</th>
      <th>Warum wir es wÃ¤hlen</th>
      <th>Im Repo?</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ruff (Backend: Python, FastAPI)</td>
      <td>Ã¼berprÃ¼ft Python-Code automatisch auf Stil-, Syntax- und QualitÃ¤tsprobleme</td>
      <td>hilft, die CodequalitÃ¤t und Lesbarkeit zu verbessern + automatisiert die ÃœberprÃ¼fung in CI/CD-Pipelines</td>
      <td>Ja â€” <code>ruff</code> ist als Devâ€‘Dependency im Backendâ€‘Projekt konfiguriert (<code>backend/pyproject.toml</code>).</td>
    </tr>
    <tr>
      <td>Eslint (Frontend: Vue.js, TypeScript)</td>
      <td>JavaScript/TypeScript-Linter fÃ¼r Frontend-Code (zB Vue.js)</td>
      <td>Ã¼berprÃ¼ft JavaScript/TypeScript-Code auf Syntax- und Stilprobleme</td>
      <td>Ja â€” ESLint ist konfiguriert; siehe <code>frontend/.eslintrc.cjs</code> und <code>frontend/package.json</code>.</td>
    </tr>
    <tr>
      <td>Unitâ€‘Test</td>
      <td>einzelne Funktionen/Methoden isoliert prÃ¼fen (zB Datenvalidierung, kleine Utils, Modellâ€‘Preprocessing)</td>
      <td>Tool: Pytest (Backend), Vitest (Frontend components)</td>
      <td>Ja â€” <code>pytest</code> ist als Devâ€‘Dependency im Backend vorhanden; Vitest ist im Frontend eingerichtet.</td>
    </tr>
    <tr>
      <td>Integrationstests</td>
      <td>mehrere Komponenten zusammen testen (zB DB + API + Modellâ€‘Wrapper)</td>
      <td>Tool: Pytest with testcontainers or local docker postgres</td>
      <td>Teilweise â€” Backend hat Testâ€‘Dependencies (pytest); <code>testcontainers</code> ist nicht offensichtlich in den AbhÃ¤ngigkeiten.</td>
    </tr>
    <tr>
      <td>Endâ€‘toâ€‘End</td>
      <td>kompletter Nutzerâ€‘Flow (Frontend + Backend + DB) aus Sicht des Nutzers testen</td>
      <td>Tool: Playwright (crossâ€‘browser), ideal fÃ¼r Demoâ€‘Regressionen</td>
      <td>Ja â€” Playwright ist im Frontend konfiguriert (<code>@playwright/test</code>, <code>playwright.config.ts</code>).</td>
    </tr>
    <tr>
      <td>pytest</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
  </tbody>
</table>

<!-- DevOps & CI: grau -->
<h3 style="background:#f7f7f7;padding:6px;border-left:6px solid #cfcfcf">DevOps & CI</h3>
<table>
  <thead>
    <tr style="background:#fafafa">
      <th>Tool</th>
      <th>Was es macht</th>
      <th>Warum wir es wÃ¤hlen</th>
      <th>Im Repo?</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Docker-Container mittels dockerâ€‘compose</td>
      <td>Verpackt alle Projektkomponenten (Backend, Frontend, Datenbank) in isolierte Container und docker-compose orchestriert diese Container lokal oder auf Servern</td>
      <td>Jeder Entwickler/ CI-Server nutzt exakt dieselbe Umgebung</td>
      <td>Ja â€” <code>docker-compose.yml</code></td>
    </tr>
    <tr>
      <td>GitHub Actions</td>
      <td>Automatisiert AblÃ¤ufe wie Linting, Unit-Tests, Integrationstests und Build-Prozesse und wird bei Pull Requests oder Releases automatisch ausgefÃ¼hrt</td>
      <td>QualitÃ¤tssicherung: PrÃ¼ft, dass Code vor dem Merge oder Deployment fehlerfrei ist + Automatisierung: Entwickler mÃ¼ssen Tests oder Builds nicht manuell starten</td>
      <td>Ja â€” <code>.github/workflows/</code></td>
    </tr>
  </tbody>
</table>

---

<a id="zeitplan"></a>
## Zeitplan (Milestones)

| Meilenstein | Datum | Kurzbeschreibung |
|---|---:|---|
| Setup Meeting | 2025â€‘10â€‘29 |  |
| MS1 (MVP) | 2025â€‘11â€‘14 | |
| MS2 (Prototype 1) | 2025â€‘11â€‘26 |H1 â€“ Backend: Predict + Feedback (Sprint ist stark backend-fokussiert, um den MVP-Flow fertigzustellen)|
| MS3 (Prototype 2) | 2025â€‘12â€‘19 |H2 â€“ Model & Explainability(SHAP) - sobald wir das Modell erhalten|
| MS4 (Release Prep) | 2026â€‘01â€‘23|H3 â€“ Frontend- & DevOps-Erweiterungen|
| Final Deliverable | 2026â€‘02â€‘27 | Abgabe aller Artefakte |

---

<a id="how-to-demo"></a>
## Demo (Skript + Beispielausgaben)

Verwende die folgenden Befehle wÃ¤hrend der PrÃ¤sentation, um den kompletten Ablauf zu demonstrieren: Dienste starten, Gesundheitscheck, einzelne Vorhersage, Ergebnis persistieren, Feedback anlegen und wieder auslesen. Alle Befehle gehen davon aus, dass das Backend unter `http://localhost:8000` erreichbar ist.

- Speichere das folgende Skript als `demo.sh` und mache es ausfÃ¼hrbar (`chmod +x demo.sh`). Es fÃ¼hrt die Sequenz aus und gibt die wichtigsten Ergebnisse aus.

```bash
#!/usr/bin/env bash
set -euo pipefail

BASE_URL=${BASE_URL:-http://localhost:8000}

echo "1) Gesundheitscheck"
curl -sS "$BASE_URL/api/v1/utils/health-check/" | jq

echo "\n2) Einzelne Vorhersage (nicht persistiert)"
curl -sS -X POST "$BASE_URL/api/v1/predict/" \
  -H "Content-Type: application/json" \
  -d '{"age":55, "hearing_loss_duration":12.5, "implant_type":"type_b"}' | jq

echo "\n3) Einzelne Vorhersage (persist=true) â€” Ergebnis wird persistiert, falls DB/Migrationen vorhanden sind"
curl -sS -X POST "$BASE_URL/api/v1/predict/?persist=true" \
  -H "Content-Type: application/json" \
  -d '{"age":55, "hearing_loss_duration":12.5, "implant_type":"type_b"}' | jq

echo "\n4) Feedback erstellen (ID speichern)"
RESP=$(curl -sS -X POST "$BASE_URL/api/v1/feedback/" \
  -H "Content-Type: application/json" \
  -d '{"input_features": {"age": 55}, "prediction": 0.23, "accepted": true}')
echo "$RESP" | jq
ID=$(echo "$RESP" | jq -r '.id')
echo "Gespeicherte Feedback-ID: $ID"

echo "\n5) Feedback nach ID lesen"
curl -sS "$BASE_URL/api/v1/feedback/$ID" | jq

echo "\nDemo-Skript beendet. Falls etwas fehlschlÃ¤gt, prÃ¼fe die Logs: docker compose logs -f backend"
```

Beispielausgaben (aus einem lokalen Lauf):

- Gesundheitscheck

```json
{ "status": "ok" }
```

- Vorhersage (einzelner Aufruf)

```json
{
  "prediction": 0.26499999999999996,
  "explanation": {
    "age": -0.030000000000000027,
    "hearing_loss_duration": -0.14999999999999997,
    "implant_type": 0.024999999999999967
  }
}
```

- Feedback erstellen (Antwort)

```json
{
  "id": "e7c6cadb-05bf-4c3b-986e-dc2881845251",
  "input_features": {"age": 55},
  "prediction": 0.23,
  "accepted": true,
  "explanation": null,
  "comment": null,
  "user_email": null,
  "created_at": "2025-11-19T16:54:38.825949"
}
```

Gespeicherte Feedbackâ€‘IDs fÃ¼r den Offlineâ€‘Fallback (falls die Demoâ€‘DB nicht beschreibbar ist):

- `e7c6cadb-05bf-4c3b-986e-dc2881845251`

Falls die Demoâ€‘Umgebung ausfÃ¤llt, Fallbackâ€‘Schritte:

- Dienste neu starten:

```bash
docker compose up --build -d
docker compose logs -f backend
```

- Schnelle manuelle PrÃ¼fungen:

```bash
curl -sS http://localhost:8000/api/v1/utils/health-check/ | jq
curl -sS -X POST http://localhost:8000/api/v1/predict/ -H "Content-Type: application/json" -d '{"age":55,"hearing_loss_duration":12.5,"implant_type":"type_b"}' | jq
```

---

<a id="system-status"></a>
## Aktueller System-Status
Docker lÃ¤uft im Kontext colima. 

Docker Compose wurde ausgefÃ¼hrt; folgende Services sind erreichbar:
  - Frontend: http://localhost:5173

  - Adminer (DB GUI): http://localhost:8080

  - Backend-API: http://localhost:8000

      - Health: http://localhost:8000/api/v1/utils/health-check/

      - Liste Patienten Ã¼ber die API (wenn Backend lÃ¤uft): curl http://localhost:8000/api/v1/patients/

      - Docs (Swagger): http://localhost:8000/docs

  - Postgres (Hostzugriff): localhost:5433 â†’ DB app, User postgres (Standardâ€‘Passwort im Repo: change_me oder aus .env)

prestart-Container lief durch (fÃ¼hrt Migrationen / initial data aus) und hat sich beendet.

**â†’ Kurzbefehle:**

| Aktion | Befehl |
|--------|--------|
| Compose starten | `cd hear-ui && docker compose up -d --build` |
| Compose stoppen | `docker compose down` |
| Logs prÃ¼fen | `docker compose logs --follow --tail 200 backend` |
| Health testen | `curl -v http://localhost:8000/api/v1/utils/health-check/` |
| Migrationen | `docker compose exec backend alembic upgrade head` |
| CSV importieren | `docker cp mydata.csv hear-ui-db-1:/tmp/mydata.csv` |

---

## API-Endpunkte (Ãœbersicht)

| Methode | Pfad | Beschreibung |
|---------|------|--------------|
| `POST` | `/api/v1/predict/` | Direkte Vorhersage |
| `POST` | `/api/v1/patients/upload` | CSV-Upload |
| `GET` | `/api/v1/patients/` | Patientenliste |
| `GET` | `/api/v1/patients/{id}` | Patient-Details |
| `GET` | `/api/v1/patients/{id}/predict` | Vorhersage fÃ¼r Patient |
| `GET` | `/api/v1/patients/{id}/explainer` | SHAP-ErklÃ¤rung fÃ¼r Patient |
| `GET` | `/api/v1/patients/{id}/validate` | Patientendaten validieren |
| `POST` | `/api/v1/explainer/explain` | Direkte SHAP-ErklÃ¤rung |
| `POST` | `/api/v1/feedback/` | Feedback erstellen |
| `GET` | `/api/v1/feedback/{id}` | Feedback lesen |
| `GET` | `/api/v1/utils/health-check/` | Gesundheitscheck |
| `GET` | `/api/v1/utils/model-info/` | Modell-Informationen |
| `GET` | `/api/v1/utils/feature-names/` | Feature-Namen |
| `GET` | `/api/v1/utils/feature-categories/` | Feature-Kategorien |

---

 ## Aktueller Projektstand (Stand: 30.11.2025)

      Kurz zusammengefasst: Das Backend (API, Modellintegration, SHAP-ErklÃ¤rungen, Feedback-Persistenz) ist implementiert und lokal in Containern lauffÃ¤hig; es existiert eine umfangreiche Testâ€‘ und Dokumentationsbasis. Das Frontend ist in Arbeit.

      **Test-Status:**
      - âœ… 164 Tests bestanden (100%)
      - â­ï¸ 2 Tests Ã¼bersprungen
      - ğŸ“Š 82% Code-Coverage

      **Patientendaten:**
      - 33 Patienten in der Datenbank (davon 17 mit vollstÃ¤ndigen Daten fÃ¼r SHAP)
      - 5 echte Patienten aus `Dummy Data_Cochlear Implant.csv` importiert
      - Vorhersage-Bereich: 22.1% - 100.0%

      Erledigtes (wichtigste Punkte):
      - Backend-API mit Endpunkten fÃ¼r Prediction, SHAP-Explanations, Feedback und Health (`/api/v1/...`) ist implementiert.
      - MLâ€‘Pipeline geladen: `logreg_best_model.pkl` (LogisticRegression mit 68 Features nach One-Hot-Encoding).
      - SHAP Explainability (Koeffizient-basiert) ist integriert; synthetische Background-Samples vorhanden.
      - Feedbackâ€‘Persistenz in PostgreSQL und Alembicâ€‘Migrationen sind eingerichtet.
      - Dockerâ€‘Compose Setup mit Backend, Frontend, Postgres und Adminer ist vorhanden; `demo.sh` automatisiert eine einfache Endâ€‘toâ€‘Endâ€‘Demonstration.
      - Tests: Backendâ€‘Unitâ€‘ und Integrationstests (Pytest) sind vorhanden und wurden ausgefÃ¼hrt (164 Tests); Testâ€‘Scripts fÃ¼r Batchâ€‘Verarbeitung liegen bei.
      - Linter/QualitÃ¤tswerkzeuge (Ruff, ESLint) und erste CI/Workflowâ€‘Konfigurationen sind vorhanden.
      - Pydantic V2 Migration abgeschlossen.
      - FastAPI Lifespan Events implementiert (keine Deprecation-Warnungen).

      Offene Aufgaben / NÃ¤chste Schritte (priorisiert):
      1. Frontendâ€‘MVP fertigstellen: UIâ€‘Formular, Anzeige der Vorhersage, SHAPâ€‘Visualisierungen (Topâ€‘5 Balken), Feedbackâ€‘UI.
      2. Featureâ€‘Nameâ€‘Mapping: Technische Featureâ€‘Bezeichnungen (`cat__...`, `num__...`) fÃ¼r Anwender in verstÃ¤ndliche Labels Ã¼bersetzen (Backendâ€‘Endpoint oder Frontendâ€‘Mapping-Datei).
      3. E2Eâ€‘Tests ergÃ¤nzen: Playwrightâ€‘Szenarien, die Formular â†’ Predict â†’ SHAP â†’ Feedback prÃ¼fen, und in CI integrieren.
      4. Integrationstests mit DB: Robustere Tests (z. B. Testcontainers oder CI Postgres) sicherstellen, dass Feedback persistiert wird.
      5. SHAP Background vergrÃ¶ÃŸern: Aktuell kleines Backgroundâ€‘Sample (5 echte / 100 synthetische); Ziel: 50â€“100 echte, vollstÃ¤ndige Patienten fÃ¼r stabilere ErklÃ¤rungen.
      6. Modellâ€‘Kalibrierung prÃ¼fen/aktivieren: Sicherstellen, dass `logreg_calibrated.pkl` in der Produktionskonfiguration verwendet und getestet wird.
      7. Security & Privacy: Authentifizierung (JWT), TLS/HTTPS, Pseudonymisierungâ€‘Policy dokumentieren und ggf. implementieren (Feedbackâ€‘Endpoint derzeit offen).
      8. Monitoring & Logging: Metriken (Prometheus/Grafana), Requestâ€‘Logs, Alerts fÃ¼r Modelâ€‘Drift und Fehler einrichten.
      9. CI/CD vervollstÃ¤ndigen: Workflows so konfigurieren, dass Lint, Tests, Alembicâ€‘Migrations und optional E2E laufen.
      10. Dokumentation & Readme: README kÃ¼rzen / strukturieren (Quickâ€‘Start, MVPâ€‘Scope prominent) â€” bereits teilweise erledigt; abschlieÃŸende Review und Linkâ€‘Badges ergÃ¤nzen.



      ---

1. Backend per Docker Compose starten: **docker compose up --build**

          â†’ startet alle in docker-compose.yml definierten Services und fÃ¼hrt sie im Hintergrund aus. Alles lokal erreichbar.
          â†’ Docker lÃ¤uft in Colima.
          â†’ **Frontend Ã¶ffnen:** http://localhost:5173 â€” UI demonstrieren (Eingabeformular â†’ Vorhersage).
          â†’ **API Docs:** http://localhost:8000/docs (Swagger) â€” Endpunkte zeigen (Predict, Feedback, Health).
          â†’ **Health-Check:** curl -sS http://localhost:8000/api/v1/utils/health-check/ | jq â€” Belegt, dass Backend lÃ¤uft. (Erwartet: {"status":"ok"} und Swaggerâ€‘UI erreichbar)
          â†’ **Liveâ€‘API-Call:** Ein curl-Beispiel zur Vorhersage zeigen (zeigt Input â†’ Output + SHAP).
          â†’ **DBâ€‘GUI (Adminer):** http://localhost:8080 â€” gespeicherte Feedbackâ€‘EintrÃ¤ge/Tabellen zeigen.
          â†’ **Logs & Migrationen:** docker compose logs -f backend + evtl. alembic upgrade head â€” Debug/State sichtbar machen.
          â†’ **Fallbacks demonstrieren: Falls Liveâ€‘Demo scheitert: Screencast/Video oder gespeicherte curl-Responses zeigen.

---

## Demo fÃ¼r MS1 â€” Exakte Patientâ€‘IDs & Howâ€‘toâ€‘Run (kurz)

Die folgenden Befehle sind fÃ¼r die Liveâ€‘Demo vorbereitet. Ersetze dabei `<PATIENT_ID>` immer durch die echte UUID.

### Wichtige Patientâ€‘IDs (mit gefÃ¼llten `input_features`, nutzbar fÃ¼r SHAP)

**Echte Patienten aus CSV (ID 1-5):**
- `9c4408e6-2aef-44c1-ae95-dd409141f647` (Patient 1 - prÃ¤lingual, 97.3%)
- `86bab602-7ffc-4663-aced-567905bed3bd` (Patient 2 - postlingual, 100%)
- `2b7414f6-471a-4bf8-8998-1385543a40b3` (Patient 3 - prÃ¤lingual/syndromal, 22.1%)
- `21bfdee0-4207-4ac2-925d-b557f14ab39e` (Patient 4 - perilingual, 81.1%)
- `a9e0736c-05fb-490b-940b-b275be3158e3` (Patient 5 - prÃ¤lingual, 97.3%)

**Test-Patienten mit vollstÃ¤ndigen Daten:**
- `0b2cbc1c-d3bf-4da6-bb18-1ffd93705754`
- `e2813011-fc6d-4f3f-a115-9effacca28ed`
- `4f016e66-3bd2-4bcf-a7ff-70ee35002903`

```bash
# Alle Patienten-IDs aus Dummy Data_Cochlear Implant.csv
curl -sS "http://localhost:8000/api/v1/patients/" | jq -r '.[].id'

# Ganze Patientenliste aus Dummy Data_Cochlear Implant.csv
curl -sS "http://localhost:8000/api/v1/patients/" | jq
```


### Kurze Ablaufâ€‘Anleitung 

1) Dienste starten

```bash
cd /Users/adeliamanafov/hearUI_project/hear-ui
docker compose up -d --build

# Laufende Container zeigen
docker compose ps
# Erwartung: backend, db (postgres) und adminer sind Up.
```

2) Healthâ€‘Check & APIâ€‘Docs

```bash
curl -sS http://localhost:8000/api/v1/utils/health-check/ | jq
# Swagger: open http://localhost:8000/docs
```

3) Alembic (falls Migrationen manuell nÃ¶tig) via Container

Alembic fÃ¼hrt die neuesten Datenbank-Migrationen aus

  - Ziel-Datenbank ist PostgreSQL
  - PostgreSQL unterstÃ¼tzt, dass Schema-Ã„nderungen (CREATE TABLE, ALTER TABLE, DROP etc.) in einer Transaktion laufen.

```bash
docker compose exec backend alembic upgrade head
```

4) Schnelle adâ€‘hocâ€‘Vorhersage (spontane/ sofortige Vorhersage)

  - nur zurÃ¼ckgegeben, aber nicht automatisch gespeichert

```bash
curl -sS -X POST "http://localhost:8000/api/v1/predict/" \
  -H "Content-Type: application/json" \
  -d '{"age":55, "hearing_loss_duration":12.5, "implant_type":"type_b"}' | jq
```

Erwartet: JSON mit `prediction` (float) und `explanation` (Objekt oder `{}`, da erklÃ¤reungen extra in shap.py erzeugt werden als in Punkt 5).

5) Persistierte Vorhersage + Feedback (Beispiel)

  - Vorhersage wird zusÃ¤tzlich in der Datenbank abgelegt, zusammen mit den Input-Daten, dem Zeitpunkt und ggf. der SHAP-ErklÃ¤rung.

```bash
curl -sS -X POST "http://localhost:8000/api/v1/predict/?persist=true" \
  -H "Content-Type: application/json" \
  -d '{"age":55, "hearing_loss_duration":12.5, "implant_type":"type_b"}' | jq

RESP=$(curl -sS -X POST "http://localhost:8000/api/v1/feedback/" \
  -H "Content-Type: application/json" \
  -d '{"input_features": {"age": 55}, "prediction": 0.23, "accepted": true}')
echo "$RESP" | jq
ID=$(echo "$RESP" | jq -r '.id')
curl -sS "http://localhost:8000/api/v1/feedback/$ID" | jq
```

6) Patientenliste + Validate (SHAPâ€‘geeignete Patienten auswÃ¤hlen)

```bash
curl -sS "http://localhost:8000/api/v1/patients/" | jq
curl -sS "http://localhost:8000/api/v1/patients/<PATIENT_ID>/validate" | jq
```

`validate` sollte `{"ok": true, "missing_features": []}` zurÃ¼ckgeben â€” dann ist der Patient SHAPâ€‘geeignet.

7) SHAP-ErklÃ¤rung fÃ¼r einen gespeicherten Patienten

```bash
curl -sS "http://localhost:8000/api/v1/patients/<PATIENT_ID>/explainer" | jq
```

Erwartet: `200 OK` und ein JSON mit `prediction`, `feature_importance`, `shap_values`, `top_features`.

8) Adâ€‘hoc SHAP (nur mit vollstÃ¤ndiger JSONâ€‘Datei)

```bash
curl -sS -X POST "http://localhost:8000/api/v1/explainer/explain" \
  -H "Content-Type: application/json" \
  -d '{"age": 45, "gender": "w", "primary_language": "Deutsch", "hearing_loss_onset": "postlingual"}' | jq
```

Hinweis: Adâ€‘hoc SHAP erfordert alle Pflichtfelder; nutze patientâ€‘based SHAP (`/patients/{id}/explainer`) wenn mÃ¶glich.

9) Logs & Liveâ€‘Debug

```bash
docker compose logs --follow --tail 200 backend
```

Typische Ursachen fÃ¼r Fehler (kurz):

- `Model not loaded` â†’ Modelldatei fehlt oder Wrapper nicht geladen (`logreg_best_pipeline.pkl` / `logreg_calibrated.pkl`).
- `ValueError` beim Casten (z. B. `invalid literal for int()`): Mapping verschoben â†’ `validate` und `input_features` prÃ¼fen.
- SHAP/NumPy ImportError: fehlende AbhÃ¤ngigkeiten.

10) Adminer / DBâ€‘Zugriff

- Adminer (DB GUI): [http://localhost:8080](http://localhost:8080)

Hostâ€‘psql (wenn nÃ¶tig):

```bash
PGPASSWORD=change_me psql -h localhost -p 5433 -U postgres -d app
```

  Formular ausfÃ¼llen (empfohlen, weil Adminer als Container im selben Dockerâ€‘Netz lÃ¤uft):
  
    - System: PostgreSQL
    - Server: db
    - Username: postgres
    - Password: changeme_secure_password_here
    - Database (optional): hear_db (Adminer lÃ¤uft in einem anderen Container, verbindet also Ã¼ber das Dockerâ€‘Netzwerk â€” dort ist der DBâ€‘Host db (der Composeâ€‘Dienstname).)
    
  Tabellenliste und Migration Status:

    docker compose exec db psql -U postgres -d hear_db -c "SELECT tablename FROM pg_tables WHERE schemaname='public' ORDER BY tablename;"

    docker compose exec db psql -U postgres -d hear_db -c "SELECT * FROM alembic_version;"

    => Was sieht man: Patient, Feedback, Vorhersage und Alembic-Version â€“ Migrationen wurden angewendet.

  API und Datenbank sind synchronisiert â€“ 33 Patienten (5 echte aus CSV + 28 Test-Patienten).



11) Fallbackâ€‘Artefakte (falls Liveâ€‘Demo scheitert)

Lege im Repo `docs/demo-fallback/` an und speichere dort:

- `predict_response.json` â€” Beispielantwort der Predictâ€‘API
- `patient_shap_response.json` â€” Beispiel SHAPâ€‘Antwort (fÃ¼r eine der obigen IDs)
- `feedback_response.json` â€” Beispiel fÃ¼r gespeichertes Feedback

```bash
# Predict live
curl -sS -X POST "http://localhost:8000/api/v1/predict/" \
  -H "Content-Type: application/json" \
  -d '{"Alter [J]": 45, "Geschlecht": "w", "PrimÃ¤re Sprache": "Deutsch"}' | jq . > docs/demo-fallback/predict_response.json

# Patient SHAP-ErklÃ¤rung (ersetze <PATIENT_ID>)
curl -sS "http://localhost:8000/api/v1/patients/<PATIENT_ID>/explainer" | jq . > docs/demo-fallback/patient_shap_response.json

# Feedback: create and save
RESP=$(curl -sS -X POST "http://localhost:8000/api/v1/feedback/" -H "Content-Type: application/json" -d '{"input_features":{"Alter [J]":55},"prediction":0.85,"accepted":true}')
echo "$RESP" | jq . > docs/demo-fallback/feedback_response.json
```

---